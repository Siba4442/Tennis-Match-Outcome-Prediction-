{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1f74ee6",
   "metadata": {},
   "source": [
    "ATP Match Prediction — Preprocessing & Feature Engineering\n",
    "\n",
    "This notebook prepares a clean, leakage-safe dataset for predicting tennis match outcomes.\n",
    "\n",
    "Outputs:\n",
    "\n",
    "data/processed/final_features.parquet containing engineered features, RESULT (label), and TOURNEY_DATE for time-based splitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817cdeba",
   "metadata": {},
   "source": [
    "Imports\n",
    "\n",
    "Import core Python libraries for data processing, feature engineering, and plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0d4107a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict, deque\n",
    "from statistics import mean\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b918fa5",
   "metadata": {},
   "source": [
    "Load raw match data\n",
    "\n",
    "Load ATP match CSV files across years and concatenate into one dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df7e7af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally - using local data directory...\n",
      "✓ Data directory found: ../data/raw/tennis_atp\n",
      "\n",
      "DATA_DIR set to: ../data/raw/tennis_atp\n"
     ]
    }
   ],
   "source": [
    "# Check if running in Google Colab or locally\n",
    "try:\n",
    "    import google.colab\n",
    "\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "# Setup data directory and download if needed\n",
    "if IN_COLAB:\n",
    "    print(\"Running in Google Colab - downloading data...\")\n",
    "    # Navigate to /content directory\n",
    "    if os.getcwd() != \"/content\":\n",
    "        os.chdir(\"/content\")\n",
    "\n",
    "    # Clone tennis_atp repository if not already present\n",
    "    if not os.path.exists(\"tennis_atp\"):\n",
    "        print(\"Cloning tennis_atp repository...\")\n",
    "        get_ipython().system(\"git clone https://github.com/JeffSackmann/tennis_atp\")\n",
    "    else:\n",
    "        print(\"tennis_atp repository already exists\")\n",
    "\n",
    "    DATA_DIR = \"/content/tennis_atp\"\n",
    "else:\n",
    "    print(\"Running locally - using local data directory...\")\n",
    "    # For local environment, use relative path from project root\n",
    "    # Assumes notebook is in: Tennies_prediction/notebook/\n",
    "    # Data should be in: Tennies_prediction/data/raw/tennis_atp/\n",
    "    DATA_DIR = \"../data/raw/tennis_atp\"\n",
    "\n",
    "    # Check if data directory exists\n",
    "    if not os.path.exists(DATA_DIR):\n",
    "        print(f\"\\n⚠️  WARNING: Data directory not found at {DATA_DIR}\")\n",
    "        print(\"Please download the tennis_atp data:\")\n",
    "        print(\"  git clone https://github.com/JeffSackmann/tennis_atp.git ../data/raw/tennis_atp\")\n",
    "        print(\"Or manually download CSV files to that location.\")\n",
    "        raise FileNotFoundError(f\"Data directory not found: {DATA_DIR}\")\n",
    "    else:\n",
    "        print(f\"✓ Data directory found: {DATA_DIR}\")\n",
    "\n",
    "print(f\"\\nDATA_DIR set to: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6d5f4a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/tennis_atp/atp_matches_1992.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m year \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1992\u001b[39m, \u001b[32m2025\u001b[39m):\n\u001b[32m      6\u001b[39m     path = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATA_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/atp_matches_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     all_data.append(\u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     10\u001b[39m all_data = pd.concat(all_data, ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     11\u001b[39m all_data.shape\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sibap\\Programming\\Tennies_prediction\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sibap\\Programming\\Tennies_prediction\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sibap\\Programming\\Tennies_prediction\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sibap\\Programming\\Tennies_prediction\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sibap\\Programming\\Tennies_prediction\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/content/tennis_atp/atp_matches_1992.csv'"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"/content/tennis_atp\"  # adjust if needed\n",
    "\n",
    "\n",
    "all_data = []\n",
    "for year in range(1992, 2025):\n",
    "    path = f\"{DATA_DIR}/atp_matches_{year}.csv\"\n",
    "    all_data.append(pd.read_csv(path))\n",
    "\n",
    "\n",
    "all_data = pd.concat(all_data, ignore_index=True)\n",
    "all_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef35768",
   "metadata": {},
   "source": [
    "Chronological ordering (prevents leakage)\n",
    "\n",
    "All rolling features (form, H2H, Elo) must be computed using only past matches. We enforce chronological ordering using tourney_date and match_num."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06071f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data.sort_values([\"tourney_date\", \"match_num\"]).reset_index(drop=True)\n",
    "all_data[[\"tourney_date\", \"match_num\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc9ae70",
   "metadata": {},
   "source": [
    "Data filtering\n",
    "\n",
    "Keep only rows with the minimum required fields for feature engineering (IDs, ranks/points, surface, and serve/break-point stats). Drop missing values to avoid NaNs during rolling calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfedb2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "needed = [\n",
    "    \"winner_id\",\n",
    "    \"loser_id\",\n",
    "    \"winner_ht\",\n",
    "    \"loser_ht\",\n",
    "    \"winner_age\",\n",
    "    \"loser_age\",\n",
    "    \"w_ace\",\n",
    "    \"w_df\",\n",
    "    \"w_svpt\",\n",
    "    \"w_1stIn\",\n",
    "    \"w_1stWon\",\n",
    "    \"w_2ndWon\",\n",
    "    \"w_SvGms\",\n",
    "    \"l_ace\",\n",
    "    \"l_df\",\n",
    "    \"l_svpt\",\n",
    "    \"l_1stIn\",\n",
    "    \"l_1stWon\",\n",
    "    \"l_2ndWon\",\n",
    "    \"l_SvGms\",\n",
    "    \"l_bpSaved\",\n",
    "    \"l_bpFaced\",\n",
    "    \"w_bpSaved\",\n",
    "    \"w_bpFaced\",\n",
    "    \"winner_rank_points\",\n",
    "    \"loser_rank_points\",\n",
    "    \"winner_rank\",\n",
    "    \"loser_rank\",\n",
    "    \"surface\",\n",
    "    \"best_of\",\n",
    "    \"draw_size\",\n",
    "    \"tourney_date\",\n",
    "    \"match_num\",\n",
    "]\n",
    "\n",
    "\n",
    "df = all_data.dropna(subset=needed).reset_index(drop=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ee475e",
   "metadata": {},
   "source": [
    "Sanity checks\n",
    "\n",
    "Verify basic properties: unique surfaces, date range, and a quick null scan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a8638f",
   "metadata": {},
   "source": [
    "print(\"date range:\", df.tourney_date.min(), df.tourney_date.max())\n",
    "print(\"surfaces:\", df.surface.dropna().unique())\n",
    "print(\"nulls in needed cols:\", df[needed].isna().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64a10dd",
   "metadata": {},
   "source": [
    "Baseline difference features\n",
    "\n",
    "Create direction-based features as (winner − loser). Later we randomize player order and flip signs to avoid label leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cca97d",
   "metadata": {},
   "source": [
    "base = pd.DataFrame(\n",
    "    {\n",
    "        \"WINNER_ID\": df[\"winner_id\"].astype(int),\n",
    "        \"LOSER_ID\": df[\"loser_id\"].astype(int),\n",
    "        \"ATP_POINT_DIFF\": df[\"winner_rank_points\"] - df[\"loser_rank_points\"],\n",
    "        \"ATP_RANK_DIFF\": df[\"winner_rank\"] - df[\"loser_rank\"],\n",
    "        \"AGE_DIFF\": df[\"winner_age\"] - df[\"loser_age\"],\n",
    "        \"HEIGHT_DIFF\": df[\"winner_ht\"] - df[\"loser_ht\"],\n",
    "        \"BEST_OF\": df[\"best_of\"].astype(int),\n",
    "        \"DRAW_SIZE\": df[\"draw_size\"].astype(int),\n",
    "        \"SURFACE\": df[\"surface\"].astype(str),\n",
    "        \"TOURNEY_DATE\": df[\"tourney_date\"].astype(int),\n",
    "    }\n",
    ")\n",
    "base.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501710b7",
   "metadata": {},
   "source": [
    "Time-aware feature builder (single pass)\n",
    "\n",
    "We compute all features using only history before each match, then update the state after the match.\n",
    "\n",
    "Features:\n",
    "\n",
    "Head-to-head overall and surface-specific\n",
    "\n",
    "Rolling win-rate differences\n",
    "\n",
    "Serve performance rolling differences\n",
    "\n",
    "Elo overall + surface Elo + Elo gradients (momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467e9c89",
   "metadata": {},
   "source": [
    "serve_windows = [3, 5, 10, 20, 50, 100, 200, 300, 2000]\n",
    "win_windows = [3, 5, 10, 25, 50, 100]\n",
    "elo_grad_windows = [5, 10, 20, 35, 50, 100, 250]\n",
    "\n",
    "\n",
    "def safe_mean(x):\n",
    "    return mean(x) if len(x) else 0.0\n",
    "\n",
    "\n",
    "# rolling state containers\n",
    "serve_hist = {\n",
    "    k: defaultdict(lambda: defaultdict(lambda: deque(maxlen=k)))\n",
    "    for k in serve_windows\n",
    "}\n",
    "win_hist = {k: defaultdict(lambda: deque(maxlen=k)) for k in win_windows}\n",
    "\n",
    "\n",
    "matches_played = defaultdict(int)\n",
    "h2h_wins = defaultdict(int)\n",
    "h2h_wins_surface = defaultdict(int)\n",
    "\n",
    "\n",
    "ELO_BASE = 1500.0\n",
    "K_BASE = 32.0\n",
    "elo_overall = defaultdict(lambda: ELO_BASE)\n",
    "elo_surface = defaultdict(lambda: defaultdict(lambda: ELO_BASE))\n",
    "elo_delta_hist = {k: defaultdict(lambda: deque(maxlen=k)) for k in elo_grad_windows}\n",
    "\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "\n",
    "def expected_score(a, b):\n",
    "    return 1.0 / (1.0 + 10.0 ** ((b - a) / 400.0))\n",
    "\n",
    "\n",
    "def k_factor(best_of):\n",
    "    return K_BASE * (1.15 if best_of == 5 else 1.0)\n",
    "\n",
    "\n",
    "def update_serve(pid, ace, df_, svpt, firstIn, firstWon, secondWon, bpSaved, bpFaced):\n",
    "    if svpt and (svpt - firstIn):\n",
    "        p_ace = 100.0 * ace / svpt\n",
    "        p_df = 100.0 * df_ / svpt\n",
    "        p_1stIn = 100.0 * firstIn / svpt\n",
    "        p_2ndWon = 100.0 * secondWon / (svpt - firstIn)\n",
    "        for k in serve_windows:\n",
    "            serve_hist[k][pid][\"p_ace\"].append(p_ace)\n",
    "            serve_hist[k][pid][\"p_df\"].append(p_df)\n",
    "            serve_hist[k][pid][\"p_1stIn\"].append(p_1stIn)\n",
    "            serve_hist[k][pid][\"p_2ndWon\"].append(p_2ndWon)\n",
    "\n",
    "    if firstIn:\n",
    "        p_1stWon = 100.0 * firstWon / firstIn\n",
    "        for k in serve_windows:\n",
    "            serve_hist[k][pid][\"p_1stWon\"].append(p_1stWon)\n",
    "\n",
    "    if bpFaced:\n",
    "        p_bpSaved = 100.0 * bpSaved / bpFaced\n",
    "        for k in serve_windows:\n",
    "            serve_hist[k][pid][\"p_bpSaved\"].append(p_bpSaved)\n",
    "\n",
    "\n",
    "rows = []\n",
    "\n",
    "\n",
    "for r in tqdm(df.itertuples(index=False), total=len(df)):\n",
    "    w = int(r.winner_id)\n",
    "    l = int(r.loser_id)\n",
    "    surface = str(r.surface)\n",
    "\n",
    "    # ----- PRE MATCH FEATURES -----\n",
    "    rec = {\n",
    "        \"PLAYER_1\": w,\n",
    "        \"PLAYER_2\": l,\n",
    "        \"ATP_POINT_DIFF\": float(r.winner_rank_points - r.loser_rank_points),\n",
    "        \"ATP_RANK_DIFF\": float(r.winner_rank - r.loser_rank),\n",
    "        \"AGE_DIFF\": float(r.winner_age - r.loser_age),\n",
    "        \"HEIGHT_DIFF\": float(r.winner_ht - r.loser_ht),\n",
    "        \"BEST_OF\": int(r.best_of),\n",
    "        \"DRAW_SIZE\": int(r.draw_size),\n",
    "        \"H2H_DIFF\": float(h2h_wins[(w, l)] - h2h_wins[(l, w)]),\n",
    "        \"H2H_SURFACE_DIFF\": float(\n",
    "            h2h_wins_surface[(w, l, surface)] - h2h_wins_surface[(l, w, surface)]\n",
    "        ),\n",
    "        \"DIFF_N_GAMES\": float(matches_played[w] - matches_played[l]),\n",
    "        \"TOURNEY_DATE\": int(r.tourney_date),\n",
    "    }\n",
    "\n",
    "    for k in win_windows:\n",
    "        rec[f\"WIN_LAST_{k}_DIFF\"] = safe_mean(win_hist[k][w]) - safe_mean(\n",
    "            win_hist[k][l]\n",
    "        )\n",
    "\n",
    "    for k in serve_windows:\n",
    "        rec[f\"P_ACE_LAST_{k}_DIFF\"] = safe_mean(\n",
    "            serve_hist[k][w][\"p_ace\"]\n",
    "        ) - safe_mean(serve_hist[k][l][\"p_ace\"])\n",
    "        rec[f\"P_DF_LAST_{k}_DIFF\"] = safe_mean(serve_hist[k][w][\"p_df\"]) - safe_mean(\n",
    "            serve_hist[k][l][\"p_df\"]\n",
    "        )\n",
    "        rec[f\"P_1ST_IN_LAST_{k}_DIFF\"] = safe_mean(\n",
    "            serve_hist[k][w][\"p_1stIn\"]\n",
    "        ) - safe_mean(serve_hist[k][l][\"p_1stIn\"])\n",
    "        rec[f\"P_1ST_WON_LAST_{k}_DIFF\"] = safe_mean(\n",
    "            serve_hist[k][w][\"p_1stWon\"]\n",
    "        ) - safe_mean(serve_hist[k][l][\"p_1stWon\"])\n",
    "        rec[f\"P_2ND_WON_LAST_{k}_DIFF\"] = safe_mean(\n",
    "            serve_hist[k][w][\"p_2ndWon\"]\n",
    "        ) - safe_mean(serve_hist[k][l][\"p_2ndWon\"])\n",
    "        rec[f\"P_BP_SAVED_LAST_{k}_DIFF\"] = safe_mean(\n",
    "            serve_hist[k][w][\"p_bpSaved\"]\n",
    "        ) - safe_mean(serve_hist[k][l][\"p_bpSaved\"])\n",
    "\n",
    "    # Elo features\n",
    "    rec[\"ELO_DIFF\"] = float(elo_overall[w] - elo_overall[l])\n",
    "    rec[\"ELO_SURFACE_DIFF\"] = float(elo_surface[w][surface] - elo_surface[l][surface])\n",
    "\n",
    "    for k in elo_grad_windows:\n",
    "        rec[f\"ELO_GRAD_{k}_DIFF\"] = safe_mean(elo_delta_hist[k][w]) - safe_mean(\n",
    "            elo_delta_hist[k][l]\n",
    "        )\n",
    "\n",
    "    # ----- POST MATCH STATE UPDATE -----\n",
    "    # Update serve stats\n",
    "    update_serve(\n",
    "        w,\n",
    "        r.w_ace,\n",
    "        r.w_df,\n",
    "        r.w_svpt,\n",
    "        r.w_1stIn,\n",
    "        r.w_1stWon,\n",
    "        r.w_2ndWon,\n",
    "        r.w_bpSaved,\n",
    "        r.w_bpFaced,\n",
    "    )\n",
    "    update_serve(\n",
    "        l,\n",
    "        r.l_ace,\n",
    "        r.l_df,\n",
    "        r.l_svpt,\n",
    "        r.l_1stIn,\n",
    "        r.l_1stWon,\n",
    "        r.l_2ndWon,\n",
    "        r.l_bpSaved,\n",
    "        r.l_bpFaced,\n",
    "    )\n",
    "\n",
    "    # Update win history\n",
    "    for k in win_windows:\n",
    "        win_hist[k][w].append(1.0)\n",
    "        win_hist[k][l].append(0.0)\n",
    "\n",
    "    # Update H2H\n",
    "    h2h_wins[(w, l)] += 1\n",
    "    h2h_wins_surface[(w, l, surface)] += 1\n",
    "\n",
    "    # Update Elo\n",
    "    K = k_factor(int(r.best_of))\n",
    "    ew = expected_score(elo_overall[w], elo_overall[l])\n",
    "    delta = K * (1.0 - ew)\n",
    "    elo_overall[w] += delta\n",
    "    elo_overall[l] -= delta\n",
    "\n",
    "    ews = expected_score(elo_surface[w][surface], elo_surface[l][surface])\n",
    "    delta_s = K * (1.0 - ews)\n",
    "    elo_surface[w][surface] += delta_s\n",
    "    elo_surface[l][surface] -= delta_s\n",
    "\n",
    "    # Record Elo gradients\n",
    "    for k in elo_grad_windows:\n",
    "        elo_delta_hist[k][w].append(delta)\n",
    "        elo_delta_hist[k][l].append(-delta)\n",
    "\n",
    "    # Update match count\n",
    "    matches_played[w] += 1\n",
    "    matches_played[l] += 1\n",
    "\n",
    "    # Randomize player order to prevent label leakage\n",
    "    if rng.random() < 0.5:\n",
    "        # swap players\n",
    "        rec[\"PLAYER_1\"], rec[\"PLAYER_2\"] = rec[\"PLAYER_2\"], rec[\"PLAYER_1\"]\n",
    "        rec[\"RESULT\"] = 0\n",
    "        for key in rec:\n",
    "            if key.endswith(\"_DIFF\"):\n",
    "                rec[key] = -rec[key]\n",
    "    else:\n",
    "        rec[\"RESULT\"] = 1\n",
    "\n",
    "    rows.append(rec)\n",
    "\n",
    "\n",
    "final_features = pd.DataFrame(rows)\n",
    "final_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bccf871",
   "metadata": {},
   "source": [
    "Save processed feature matrix\n",
    "\n",
    "Export the engineered dataset so training and comparison can be done in standalone .py scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb875d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_PATH = \"data/processed/final_features.parquet\"\n",
    "os.makedirs(os.path.dirname(OUT_PATH), exist_ok=True)\n",
    "final_features.to_parquet(OUT_PATH, index=False)\n",
    "print(\"saved:\", OUT_PATH, \"shape:\", final_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c853425",
   "metadata": {},
   "source": [
    "Plot: class balance\n",
    "\n",
    "Confirm RESULT is roughly balanced because we randomized player order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb71d77",
   "metadata": {},
   "source": [
    "plt.figure()\n",
    "final_features[\"RESULT\"].value_counts().sort_index().plot(kind=\"bar\")\n",
    "plt.xlabel(\"RESULT (1 = PLAYER_1 wins)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Class Balance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002a1f0d",
   "metadata": {},
   "source": [
    "Plot: feature distributions\n",
    "\n",
    "Visualize key engineered features to verify reasonable ranges and detect extreme outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9aa693",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"ATP_POINT_DIFF\", \"ATP_RANK_DIFF\", \"ELO_DIFF\", \"H2H_DIFF\", \"WIN_LAST_50_DIFF\"]\n",
    "for c in cols:\n",
    "    plt.figure()\n",
    "    plt.hist(final_features[c], bins=60)\n",
    "    plt.title(f\"Distribution: {c}\")\n",
    "    plt.xlabel(c)\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1deab4d",
   "metadata": {},
   "source": [
    "Plot: correlation among key features\n",
    "\n",
    "Check correlation structure among high-level features (Elo, rank/points, win form). Trees handle correlation well, but this helps interpret redundancy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f72e3c",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "corr_cols = [\n",
    "    \"ATP_POINT_DIFF\",\n",
    "    \"ATP_RANK_DIFF\",\n",
    "    \"ELO_DIFF\",\n",
    "    \"ELO_SURFACE_DIFF\",\n",
    "    \"WIN_LAST_10_DIFF\",\n",
    "    \"WIN_LAST_50_DIFF\",\n",
    "    \"H2H_DIFF\",\n",
    "    \"H2H_SURFACE_DIFF\",\n",
    "]\n",
    "C = final_features[corr_cols].corr().values\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(C, aspect=\"auto\")\n",
    "plt.xticks(range(len(corr_cols)), corr_cols, rotation=45, ha=\"right\")\n",
    "plt.yticks(range(len(corr_cols)), corr_cols)\n",
    "plt.title(\"Correlation Heatmap (selected features)\")\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e067978",
   "metadata": {},
   "source": [
    "Player ID → Name mapping\n",
    "\n",
    "Load player metadata so we can select famous players and plot their Elo trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94dfb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "players_path = f\"{DATA_DIR}/atp_players.csv\"\n",
    "players = pd.read_csv(players_path)\n",
    "players[\"name\"] = (\n",
    "    players[\"name_first\"].fillna(\"\") + \" \" + players[\"name_last\"].fillna(\"\")\n",
    ")\n",
    "player_name = dict(zip(players[\"player_id\"], players[\"name\"]))\n",
    "players.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df45e1e2",
   "metadata": {},
   "source": [
    "Elo time-series extraction\n",
    "\n",
    "Re-run a lightweight chronological pass to record Elo values after each match for selected players. We track overall Elo and surface-specific Elo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eac3751",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_names = [\"Novak Djokovic\", \"Rafael Nadal\", \"Roger Federer\", \"Andy Murray\"]\n",
    "selected_ids = [pid for pid, nm in player_name.items() if nm in selected_names]\n",
    "selected_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77458f4a",
   "metadata": {},
   "source": [
    "Build Elo history table\n",
    "\n",
    "Construct a long-format dataset of Elo points over time for each selected player and each surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce71927c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "ELO_BASE = 1500.0\n",
    "K_BASE = 32.0\n",
    "\n",
    "\n",
    "elo_overall_ts = defaultdict(list)  # pid -> list of (date, elo)\n",
    "elo_surface_ts = defaultdict(\n",
    "    lambda: defaultdict(list)\n",
    ")  # pid -> surface -> list of (date, elo)\n",
    "\n",
    "\n",
    "elo_o = defaultdict(lambda: ELO_BASE)\n",
    "elo_s = defaultdict(lambda: defaultdict(lambda: ELO_BASE))\n",
    "\n",
    "\n",
    "def expected_score(a, b):\n",
    "    return 1.0 / (1.0 + 10.0 ** ((b - a) / 400.0))\n",
    "\n",
    "\n",
    "def k_factor(best_of):\n",
    "    return K_BASE * (1.15 if best_of == 5 else 1.0)\n",
    "\n",
    "\n",
    "for r in tqdm(df.itertuples(index=False), total=len(df)):\n",
    "    w = int(r.winner_id)\n",
    "    l = int(r.loser_id)\n",
    "    surface = str(r.surface)\n",
    "    date = int(r.tourney_date)\n",
    "\n",
    "    K = k_factor(int(r.best_of))\n",
    "\n",
    "    ew = expected_score(elo_o[w], elo_o[l])\n",
    "    delta = K * (1.0 - ew)\n",
    "    elo_o[w] += delta\n",
    "    elo_o[l] -= delta\n",
    "\n",
    "    ews = expected_score(elo_s[w][surface], elo_s[l][surface])\n",
    "    delta_s = K * (1.0 - ews)\n",
    "    elo_s[w][surface] += delta_s\n",
    "    elo_s[l][surface] -= delta_s\n",
    "\n",
    "    # record if selected\n",
    "    if w in selected_ids:\n",
    "        elo_overall_ts[w].append((date, float(elo_o[w])))\n",
    "        elo_surface_ts[w][surface].append((date, float(elo_s[w][surface])))\n",
    "    if l in selected_ids:\n",
    "        elo_overall_ts[l].append((date, float(elo_o[l])))\n",
    "        elo_surface_ts[l][surface].append((date, float(elo_s[l][surface])))\n",
    "\n",
    "\n",
    "# convert to dataframe\n",
    "rows_ts = []\n",
    "for pid, pts in elo_overall_ts.items():\n",
    "    for d, e in pts:\n",
    "        rows_ts.append(\n",
    "            {\n",
    "                \"player_id\": pid,\n",
    "                \"name\": player_name.get(pid, str(pid)),\n",
    "                \"date\": d,\n",
    "                \"elo\": e,\n",
    "                \"type\": \"overall\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "\n",
    "for pid, bys in elo_surface_ts.items():\n",
    "    for surf, pts in bys.items():\n",
    "        for d, e in pts:\n",
    "            rows_ts.append(\n",
    "                {\n",
    "                    \"player_id\": pid,\n",
    "                    \"name\": player_name.get(pid, str(pid)),\n",
    "                    \"date\": d,\n",
    "                    \"elo\": e,\n",
    "                    \"type\": f\"surface:{surf}\",\n",
    "                }\n",
    "            )\n",
    "\n",
    "\n",
    "elo_df = pd.DataFrame(rows_ts)\n",
    "elo_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff1a5c5",
   "metadata": {},
   "source": [
    "Plot: Surface-specific Elo\n",
    "\n",
    "Compare how a single player performs across different surfaces by plotting surface Elo time-series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba105c3",
   "metadata": {},
   "source": [
    "surfaces = [\"Hard\", \"Clay\", \"Grass\"]\n",
    "\n",
    "\n",
    "for name in selected_names:\n",
    "    pid = [p for p, nm in player_name.items() if nm == name][0]\n",
    "    plt.figure()\n",
    "    for s in surfaces:\n",
    "        sub = elo_df[\n",
    "            (elo_df[\"player_id\"] == pid) & (elo_df[\"type\"] == f\"surface:{s}\")\n",
    "        ].sort_values(\"date\")\n",
    "        if len(sub) == 0:\n",
    "            continue\n",
    "        plt.plot(sub[\"date\"].values, sub[\"elo\"].values, label=s)\n",
    "    plt.title(f\"Surface Elo: {name}\")\n",
    "    plt.xlabel(\"Date (YYYYMMDD)\")\n",
    "    plt.ylabel(\"Surface Elo\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3974a02",
   "metadata": {},
   "source": [
    "Quick baseline (sklearn tree)\n",
    "\n",
    "Train a quick baseline model inside the notebook to validate the pipeline. The full training workflow lives in src/train_sklearn.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c488cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "split_date = 20221231\n",
    "train_mask = final_features[\"TOURNEY_DATE\"].values <= split_date\n",
    "\n",
    "\n",
    "y = final_features[\"RESULT\"].astype(int).values\n",
    "X = final_features.drop(columns=[\"RESULT\", \"TOURNEY_DATE\"]).values\n",
    "\n",
    "\n",
    "X_train, y_train = X[train_mask], y[train_mask]\n",
    "X_test, y_test = X[~train_mask], y[~train_mask]\n",
    "\n",
    "\n",
    "model = DecisionTreeClassifier(\n",
    "    max_depth=6, min_samples_split=200, min_samples_leaf=100, random_state=42\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "print(\"accuracy:\", accuracy_score(y_test, pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tennies_prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
